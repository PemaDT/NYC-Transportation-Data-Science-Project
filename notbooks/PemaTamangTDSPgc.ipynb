{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        " #TO DO: Begin creating here!import pandas as pd\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import folium\n",
        "import datetime\n",
        "from datetime import date\n"
      ],
      "metadata": {
        "id": "krM4R5_8069_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "PwvapjiQyAXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Read the data using pandas read_csv function\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/Motor_Vehicle_Collisions_-_Crashes_20241015.csv\", low_memory=False)"
      ],
      "metadata": {
        "id": "1QAcxq5KyDRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating the range of crash date\n",
        "# Convert 'CRASH DATE' to datetime if it's not already\n",
        "data['CRASH DATE'] = pd.to_datetime(data['CRASH DATE'])\n",
        "\n",
        "# Find the minimum and maximum crash dates\n",
        "min_date = data['CRASH DATE'].min()\n",
        "max_date = data['CRASH DATE'].max()\n",
        "\n",
        "print(f\"The range of crash dates is from {min_date} to {max_date}\")"
      ],
      "metadata": {
        "id": "UGohwWDMyLId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Print the first 5 rows of the data using head function of pandas\n",
        "data.head(5)"
      ],
      "metadata": {
        "id": "t3_zrES_yRQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bar chart to compare the number of crashes that occurred in each of the five boroughs in descending order use cubehelix palette\n",
        "# Group by borough and count the number of crashes\n",
        "borough_crashes = data.groupby('BOROUGH')['BOROUGH'].count()\n",
        "\n",
        "# Sort the boroughs in descending order of crash counts\n",
        "borough_crashes = borough_crashes.sort_values(ascending=False)\n",
        "\n",
        "# Plotting the bar chart with cubehelix palette\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=borough_crashes.index, y=borough_crashes.values, palette=\"cubehelix\")\n",
        "plt.title('Number of Crashes per Borough (Descending Order)')\n",
        "plt.xlabel('Borough')\n",
        "plt.ylabel('Number of Crashes')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cuhFsAGRyUdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bar chart for crashes by days in spelling in descending order using cubehelix palette\n",
        "# Convert 'CRASH DATE' to datetime if it's not already\n",
        "data['CRASH DATE'] = pd.to_datetime(data['CRASH DATE'])\n",
        "\n",
        "# Extract the day of the week\n",
        "data['DAY_OF_WEEK'] = data['CRASH DATE'].dt.day_name()\n",
        "\n",
        "# Count crashes for each day of the week\n",
        "crashes_by_day = data['DAY_OF_WEEK'].value_counts()\n",
        "\n",
        "# Create the side bar chart with cubehelix palette and descending order\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=crashes_by_day.index, y=crashes_by_day.values, palette=\"cubehelix\")\n",
        "plt.title('Crashes by Day of Week (Descending Order)')\n",
        "plt.xlabel('Day of Week')\n",
        "plt.ylabel('Number of Crashes')\n",
        "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uMQAEbSLyZBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pie chart for Crashes\n",
        "# Calculate borough_crashes here\n",
        "borough_crashes = data.groupby('BOROUGH')['BOROUGH'].count()\n",
        "\n",
        "# Create the pie chart with the cubehelix palette and highlight the highest\n",
        "plt.figure(figsize=(8, 8))\n",
        "explode = [0.1 if i == borough_crashes.idxmax() else 0 for i in borough_crashes.index]  # Explode the highest\n",
        "plt.pie(borough_crashes, labels=borough_crashes.index, autopct='%1.1f%%', startangle=90, explode=explode, colors=sns.cubehelix_palette(len(borough_crashes)))\n",
        "plt.title('Distribution of Crashes Across Boroughs')\n",
        "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "h0AK5Gg9yc7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ADDING NEW DATA NYPD ARREST.\n",
        "file_path =\"/content/drive/MyDrive/NYPD_Arrest_Data__Year_to_Date__20241109.csv\"\n",
        "data = pd.read_csv(file_path, low_memory=False)"
      ],
      "metadata": {
        "id": "yisS1gPYyhEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arrest = pd.read_csv(\"/content/drive/MyDrive/NYPD_Arrest_Data__Year_to_Date__20241109.csv\")\n",
        "arrest[:5]"
      ],
      "metadata": {
        "id": "SlnOwwpayn8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def date_to_weekday(date):\n",
        "    weekday_dict = {0:'Monday', 1:'Tuesday', 2: 'Wednesday', 3: 'Thursday', 4: 'Friday', 5: 'Saturday', 6: 'Sunday'}\n",
        "    date_time_obj = datetime.datetime.strptime(date, '%m/%d/%Y')\n",
        "    return weekday_dict[date_time_obj.weekday()]\n",
        "\n",
        "def code_to_loc(borough):\n",
        "    code_dict = {'B': 'Bronx', 'S': 'Staten Island', 'K': 'Brooklyn', 'M': 'Manhattan' , 'Q': 'Queens'}\n",
        "    return borough if borough in code_dict.values() else code_dict.get(borough[0], borough)\n",
        "\n",
        "\n",
        "\n",
        "def code_to_fel(code):\n",
        "    code_dict = {'F': 'Felony','M': 'Misdemeanor', 'V': 'Violation', 'I': 'Other'}\n",
        "    if code in code_dict:\n",
        "        return code_dict[code]\n",
        "    else:\n",
        "        return 'Other'\n",
        "\n",
        "date = arrest['ARREST_DATE'].str.split(\"/\", n = 3, expand = True)\n",
        "arrest['year'] = date[2].astype('int32')\n",
        "arrest['day'] = date[1].astype('int32')\n",
        "arrest['month'] = date[0].astype('int32')\n",
        "\n",
        "arrest['ARREST_BORO'] = arrest['ARREST_BORO'].apply(code_to_loc)\n",
        "arrest['WEEKDAY'] = arrest['ARREST_DATE'].apply(date_to_weekday)\n",
        "arrest['LAW_CAT_CD'] = arrest['LAW_CAT_CD'].apply(code_to_fel)\n",
        "\n",
        "# Check for the existence of columns before dropping\n",
        "columns_to_drop = ['ARREST_KEY', 'PD_CD', 'PD_DESC', 'KY_CD', 'LAW_CODE', 'JURISDICTION_CODE', 'X_COORD_CD', 'Y_COORD_CD']\n",
        "existing_columns = [col for col in columns_to_drop if col in arrest.columns]\n",
        "\n",
        "# Drop only the existing columns\n",
        "arrest = arrest.drop(columns=existing_columns, errors='ignore')\n",
        "arrest[:5]"
      ],
      "metadata": {
        "id": "zzmfCZRxyrFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying bar chart to compare the number of arrests that occurred in each of the five boroughs in descending order using cubehelix palette\n",
        "# Group by borough and count the number of arrests\n",
        "borough_arrests = arrest.groupby('ARREST_BORO')['ARREST_BORO'].count()\n",
        "\n",
        "# Sort the boroughs in descending order of arrest counts\n",
        "borough_arrests = borough_arrests.sort_values(ascending=False)\n",
        "\n",
        "# Plotting the bar chart with cubehelix palette\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=borough_arrests.index, y=borough_arrests.values, palette=\"cubehelix\")\n",
        "plt.title('Number of Arrests per Borough (Descending Order)')\n",
        "plt.xlabel('Borough')\n",
        "plt.ylabel('Number of Arrests')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t4XayCSbyxWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying bar chart of arrests by day in desending order using cubehelix palette\n",
        "\n",
        "# Convert 'ARREST_DATE' to datetime objects if it isn't already\n",
        "arrest['ARREST_DATE'] = pd.to_datetime(arrest['ARREST_DATE'])\n",
        "\n",
        "# Extract the day of the week\n",
        "arrest['DAY_OF_WEEK'] = arrest['ARREST_DATE'].dt.day_name()\n",
        "\n",
        "# Count arrests for each day of the week\n",
        "arrests_by_day = arrest['DAY_OF_WEEK'].value_counts()\n",
        "\n",
        "# Create the bar chart with cubehelix palette and descending order\n",
        "plt.figure(figsize=(10, 6))\n",
        "arrests_by_day = arrests_by_day.sort_values(ascending=False)  # Sort in descending order\n",
        "sns.barplot(x=arrests_by_day.index, y=arrests_by_day.values, palette=\"cubehelix\")\n",
        "plt.title('Arrests by Day of Week (Descending Order)')\n",
        "plt.xlabel('Day of Week')\n",
        "plt.ylabel('Number of Arrests')\n",
        "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qyO919s3y121"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display the types of arrest\n",
        "\n",
        "# Display unique arrest types\n",
        "unique_arrest_types = arrest['OFNS_DESC'].unique()\n",
        "print(\"Unique Arrest Types:\")\n",
        "for arrest_type in unique_arrest_types:\n",
        "    print(arrest_type)\n",
        "\n",
        "# Or, if you want a more concise output:\n",
        "#print(\"\\nUnique Arrest Types (Concise):\\n\", arrest['OFNS_DESC'].unique())\n",
        "\n",
        "\n",
        "# You can also count the occurrences of each arrest type\n",
        "arrest_type_counts = arrest['OFNS_DESC'].value_counts()\n",
        "print(\"\\nArrest Type Counts:\\n\", arrest_type_counts)"
      ],
      "metadata": {
        "id": "0kAOiMcvy5y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating the range of arrest date\n",
        "\n",
        "# Convert 'ARREST_DATE' to datetime objects if it isn't already\n",
        "arrest['ARREST_DATE'] = pd.to_datetime(arrest['ARREST_DATE'])\n",
        "\n",
        "# Find the minimum and maximum arrest dates\n",
        "min_date = arrest['ARREST_DATE'].min()\n",
        "max_date = arrest['ARREST_DATE'].max()\n",
        "\n",
        "print(f\"The range of arrest dates is from {min_date} to {max_date}\")"
      ],
      "metadata": {
        "id": "j2R3Hsjpy9dC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calulating VTL percentages\n",
        "# Filter for Vehicle and Traffic Laws related offenses\n",
        "vehicle_traffic_arrests = arrest[arrest['OFNS_DESC'].str.contains(\"VEHICLE\", na=False) | arrest['OFNS_DESC'].str.contains(\"TRAFFIC\", na=False)]\n",
        "\n",
        "# Calculate the total number of arrests\n",
        "total_arrests = len(arrest)\n",
        "\n",
        "# Calculate the number of vehicle and traffic arrests\n",
        "vehicle_traffic_count = len(vehicle_traffic_arrests)\n",
        "\n",
        "# Calculate the percentage\n",
        "percentage_vehicle_traffic = (vehicle_traffic_count / total_arrests) * 100\n",
        "\n",
        "print(f\"The percentage of arrests related to Vehicle and Traffic Laws is: {percentage_vehicle_traffic:.2f}%\")"
      ],
      "metadata": {
        "id": "z-KEzaw3zBX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating pie chart\n",
        "# Group data by borough\n",
        "borough_counts = arrest['ARREST_BORO'].value_counts()\n",
        "\n",
        "# Create the pie chart\n",
        "plt.figure(figsize=(8, 8))\n",
        "colors = sns.cubehelix_palette(len(borough_counts)) # Use cubehelix palette\n",
        "explode = [0.1 if i == borough_counts.idxmax() else 0 for i in borough_counts.index]  # Explode the largest slice\n",
        "plt.pie(borough_counts, labels=borough_counts.index, autopct='%1.1f%%', startangle=90, colors=colors, explode=explode)\n",
        "plt.title('Arrest Distribution by Borough')\n",
        "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "69ZLr70xzFV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lDIqPCXVzIHE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}